\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Evaluation}{29}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:five}{{5}{29}{Evaluation}{chapter.5}{}}
\newlabel{chap:five@cref}{{[chapter][5][]5}{[1][29][]29}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Comparison Objectives}{29}{section.5.1}\protected@file@percent }
\newlabel{sec:comparison objectives}{{5.1}{29}{Comparison Objectives}{section.5.1}{}}
\newlabel{sec:comparison objectives@cref}{{[section][1][5]5.1}{[1][29][]29}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces An overview of instance segmentation models compared in this work. $(^*)$ : as described in \Cref  {sec:instance_segmentation_models}, C2Fseg models crop input images based on visible regions and resize each region of interest (ROI) to $256^2$ px.}}{30}{table.caption.16}\protected@file@percent }
\newlabel{tab:ISmodels}{{5.1}{30}{An overview of instance segmentation models compared in this work. $(^*)$ : as described in \Cref {sec:instance_segmentation_models}, C2Fseg models crop input images based on visible regions and resize each region of interest (ROI) to $256^2$ px}{table.caption.16}{}}
\newlabel{tab:ISmodels@cref}{{[table][1][5]5.1}{[1][29][]30}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Evaluation Metrics}{30}{section.5.2}\protected@file@percent }
\newlabel{sec:evaluation metrics}{{5.2}{30}{Evaluation Metrics}{section.5.2}{}}
\newlabel{sec:evaluation metrics@cref}{{[section][2][5]5.2}{[1][30][]30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Intersection over Union}{30}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Average Precision}{31}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}2D Quantitative Analysis}{31}{section.5.3}\protected@file@percent }
\newlabel{sec:quan_2d}{{5.3}{31}{2D Quantitative Analysis}{section.5.3}{}}
\newlabel{sec:quan_2d@cref}{{[section][3][5]5.3}{[1][31][]31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}YOLO Models Quantitative Analysis}{31}{subsection.5.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces A comparative quantitive results of the YOLO instance segmentation models on the segmentation annotation extended test set. The models are evaluated on image sizes of 1920, 1280, and 640 with a confidence threshold of 0.25.}}{32}{table.caption.17}\protected@file@percent }
\newlabel{tab:2d_quantitative_yolo}{{5.2}{32}{A comparative quantitive results of the YOLO instance segmentation models on the segmentation annotation extended test set. The models are evaluated on image sizes of 1920, 1280, and 640 with a confidence threshold of 0.25}{table.caption.17}{}}
\newlabel{tab:2d_quantitative_yolo@cref}{{[table][2][5]5.2}{[1][31][]32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}C2F Models Quantitative Analysis}{33}{subsection.5.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces A quantitative comparison of different C2F amodal instance segmentation models on the segmentation annotation extended test set. Full mIoU represents the mIoU of the complete object mask, incorporating both visible and occluded parts. All models utilize ground truth instance segmentation masks as visible detection inputs.}}{33}{table.caption.18}\protected@file@percent }
\newlabel{tab:2d_amodal_quantitative}{{5.3}{33}{A quantitative comparison of different C2F amodal instance segmentation models on the segmentation annotation extended test set. Full mIoU represents the mIoU of the complete object mask, incorporating both visible and occluded parts. All models utilize ground truth instance segmentation masks as visible detection inputs}{table.caption.18}{}}
\newlabel{tab:2d_amodal_quantitative@cref}{{[table][3][5]5.3}{[1][32][]33}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Inference Speed}{33}{section.5.4}\protected@file@percent }
\newlabel{sec:inference_speed}{{5.4}{33}{Inference Speed}{section.5.4}{}}
\newlabel{sec:inference_speed@cref}{{[section][4][5]5.4}{[1][33][]33}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces A Comparison of model inference speed (FPS) across various image resolutions. The results highlight significant acceleration in inference speed with the YOLOv8 model, especially after exporting to TensorRT.}}{34}{table.caption.19}\protected@file@percent }
\newlabel{tab:model_speed_resolutions_combined}{{5.4}{34}{A Comparison of model inference speed (FPS) across various image resolutions. The results highlight significant acceleration in inference speed with the YOLOv8 model, especially after exporting to TensorRT}{table.caption.19}{}}
\newlabel{tab:model_speed_resolutions_combined@cref}{{[table][4][5]5.4}{[1][33][]34}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}3D Perception Performance Analysis}{34}{section.5.5}\protected@file@percent }
\newlabel{sec:quan_3d}{{5.5}{34}{3D Perception Performance Analysis}{section.5.5}{}}
\newlabel{sec:quan_3d@cref}{{[section][5][5]5.5}{[1][34][]34}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces An illustration of YOLOv8x\_coco\_tumtraf\_1920 model detecting two adjacent large objects as a single object mask.}}{34}{figure.5.1}\protected@file@percent }
\newlabel{fig:single_mask}{{5.1}{34}{An illustration of YOLOv8x\_coco\_tumtraf\_1920 model detecting two adjacent large objects as a single object mask}{figure.5.1}{}}
\newlabel{fig:single_mask@cref}{{[figure][1][5]5.1}{[1][34][]34}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces This table presents the 3D detection quantitative results on the test sequence of TUMTraf Intersection Dataset from both camera south1 and camera south2. To make the table more readable, classes with Precision, Recall and AP of 0 are not shown here. Classes with labels in ground truth but no detections have an AP value of 0 and are still included in the mAP calculation. However, classes without labels in ground truth and with no detections are excluded and do not contribute to the mAP.}}{35}{table.caption.20}\protected@file@percent }
\newlabel{tab:3d_quantitative_yolo}{{5.5}{35}{This table presents the 3D detection quantitative results on the test sequence of TUMTraf Intersection Dataset from both camera south1 and camera south2. To make the table more readable, classes with Precision, Recall and AP of 0 are not shown here. Classes with labels in ground truth but no detections have an AP value of 0 and are still included in the mAP calculation. However, classes without labels in ground truth and with no detections are excluded and do not contribute to the mAP}{table.caption.20}{}}
\newlabel{tab:3d_quantitative_yolo@cref}{{[table][5][5]5.5}{[1][34][]35}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces An Illustration comparing ground truth (green) with YOLOv8x\_tumtraf predictions (red). These frames are from the TUMTraf Intersection Dataset test sequence. The frames reveal that the labels of the TUMTraf Intersection Dataset are incomplete, failing to label all objects in the image. Consequently, the models produce false positives when identifying unlabeled objects.}}{36}{figure.5.2}\protected@file@percent }
\newlabel{fig:groundtruth_vs_finetuned_testSouth1}{{5.2}{36}{An Illustration comparing ground truth (green) with YOLOv8x\_tumtraf predictions (red). These frames are from the TUMTraf Intersection Dataset test sequence. The frames reveal that the labels of the TUMTraf Intersection Dataset are incomplete, failing to label all objects in the image. Consequently, the models produce false positives when identifying unlabeled objects}{figure.5.2}{}}
\newlabel{fig:groundtruth_vs_finetuned_testSouth1@cref}{{[figure][2][5]5.2}{[1][36][]36}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Qualitative Analysis}{36}{section.5.6}\protected@file@percent }
\newlabel{sec:qual}{{5.6}{36}{Qualitative Analysis}{section.5.6}{}}
\newlabel{sec:qual@cref}{{[section][6][5]5.6}{[1][36][]36}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Qualitative comparison results of different models on TUMTraf Intersection Dataset. From top to bottom: a) $YOLOv7\_coco$, b) $YOLOv8x\_coco$, c) $YOLOv8x\_tumtraf$, d) $YOLOv8x\_coco\_tumtraf\_1920$, e) $C2F\_kins\_tumtraf\_1920$. The visualizations include 2D bounding boxes, 2D masks, 3D bounding boxes, and category labels.}}{37}{figure.caption.21}\protected@file@percent }
\newlabel{fig:qualitative_result}{{5.3}{37}{Qualitative comparison results of different models on TUMTraf Intersection Dataset. From top to bottom: a) $YOLOv7\_coco$, b) $YOLOv8x\_coco$, c) $YOLOv8x\_tumtraf$, d) $YOLOv8x\_coco\_tumtraf\_1920$, e) $C2F\_kins\_tumtraf\_1920$. The visualizations include 2D bounding boxes, 2D masks, 3D bounding boxes, and category labels}{figure.caption.21}{}}
\newlabel{fig:qualitative_result@cref}{{[figure][3][5]5.3}{[1][36][]37}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Illustrations comparing bottom contour extraction from amodal masks generated by C2F (first row) and from visible masks only by YOLO models (second row). Bottom contours of occluded objects can be detected accurately from amodal masks.}}{38}{figure.5.4}\protected@file@percent }
\newlabel{fig:bottom_contour}{{5.4}{38}{Illustrations comparing bottom contour extraction from amodal masks generated by C2F (first row) and from visible masks only by YOLO models (second row). Bottom contours of occluded objects can be detected accurately from amodal masks}{figure.5.4}{}}
\newlabel{fig:bottom_contour@cref}{{[figure][4][5]5.4}{[1][38][]38}}
\@setckpt{source/chapter05}{
\setcounter{page}{39}
\setcounter{equation}{0}
\setcounter{enumi}{5}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{SelectedStyles}{1}
\setcounter{SelectedModules}{13}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{5}
\setcounter{AM@survey}{0}
\setcounter{mdf@globalstyle@cnt}{1}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{0}
\setcounter{parentequation}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{97}
\setcounter{maxnames}{99}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{3}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{2}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{blindtext}{1}
\setcounter{Blindtext}{5}
\setcounter{blind@countparstart}{0}
\setcounter{blindlist}{0}
\setcounter{blindlistlevel}{0}
\setcounter{blindlist@level}{0}
\setcounter{blind@listcount}{0}
\setcounter{blind@levelcount}{0}
\setcounter{blind@randomcount}{0}
\setcounter{blind@randommax}{0}
\setcounter{blind@pangramcount}{0}
\setcounter{blind@pangrammax}{0}
\setcounter{pc@count@i}{0}
\setcounter{pc@count@ii}{0}
\setcounter{pc@count@iii}{0}
\setcounter{pc@count@iv}{0}
\setcounter{zref@unique}{0}
\setcounter{mn@abspage}{47}
\setcounter{section@level}{0}
\setcounter{Item}{15}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{46}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{float@type}{16}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{1}
\setcounter{ALG@blocknr}{1}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{lstnumber}{13}
\setcounter{lstlisting}{0}
}
